import pandas as pd
df= pd.read_csv("wind_power_combined.csv")
df



from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler

# Features (X) are 'Air temperature | (°C)', 'Pressure | (atm)', and 'Wind speed | (m/s)'
# Target (y) is 'Power generated by system | (MW)'

# Extracting features (X) and target (y)
X = df[['Air temperature | (°C)', 'Pressure | (atm)', 'Wind speed | (m/s)']]
y = df['Power generated by system | (MW)']

# Splitting the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# Initialize the Random Forest regressor
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)

# Training the Random Forest regressor
rf_regressor.fit(X_train, y_train)

# Predicting on the test set
y_pred = rf_regressor.predict(X_test)

# Evaluating the model using metrics
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Absolute Error:", mae)
print("Mean Squared Error:", mse)
print("R-squared:", r2)



# Load the forecasted data for 2024
forecasted_data_2024 = pd.read_excel("wind_test_data.xlsx")

# Extracting features for prediction
X_forecasted = forecasted_data_2024[['Air temperature | (°C)', 'Pressure | (atm)', 'Wind speed | (m/s)']]

# Predict power generation using the trained Random Forest regressor
predictions = rf_regressor.predict(X_forecasted)

# Print or save the predictions
print("Predicted power generation for 2024:")
print(predictions)




predictions.sum()



# Step 1: Load the data
data = pd.read_csv("final_data.csv")

# Step 2: Calculate the total power generated
total_power_generated = data['p1'].sum() + data['p2'].sum() + data['p3'].sum()

# Step 3: Distribute the power to each node based on the specified percentages
power_node1 = total_power_generated * 0.20  # 20% of total power
power_node2 = total_power_generated * 0.45  # 45% of total power
power_node3 = total_power_generated * 0.35  # 35% of total power

# Step 4: Prepare a DataFrame to store the distributed power for each node
node_data = {
    'Node': ['Node 1', 'Node 2', 'Node 3'],
    'Power Generated (MW)': [power_node1, power_node2, power_node3]
}

# Create a DataFrame
power_distribution_df = pd.DataFrame(node_data)

# Calculate the total power generated including P1, P2, and P3
total_power_generated_all = total_power_generated + data['p1'].sum() + data['p2'].sum() + data['p3'].sum()

# Check if generated and distributed powers are equal
equal_powers = total_power_generated == (power_node1 + power_node2 + power_node3)

# Display the DataFrame
print(power_distribution_df)

# Display the total power generated
print("Total Power Generated (including P1, P2, P3):", total_power_generated_all, "MW")

# Display if generated and distributed powers are equal
print("Generated and Distributed Powers are Equal:", equal_powers)



total_power_generated_all


# Step 1: Create new columns for each node
data['Power_Node_1'] = data['Power generated by system | (MW)'] * 0.20  # 20% of total power
data['Power_Node_2'] = data['Power generated by system | (MW)'] * 0.45  # 45% of total power
data['Power_Node_3'] = data['Power generated by system | (MW)'] * 0.35  # 35% of total power

# Step 2: Optionally, drop the original columns
data.drop(columns=['Power generated by system | (MW)'], inplace=True)

# Step 3: Display the updated DataFrame
print(data)



data.head()


data.to_csv("new_datset")


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Assuming 'data' contains your dataset with features and 'stability' column
# Split the dataset into features and target
X = data.drop(columns=['stability', 'date'])  # Remove 'date' column if not needed
y = data['stability']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize the logistic regression model
logistic_regression_model = LogisticRegression()

# Train the model
logistic_regression_model.fit(X_train_scaled, y_train)

# Predict on the test set
y_pred = logistic_regression_model.predict(X_test_scaled)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Test Accuracy:", accuracy)

# Print classification report
print(classification_report(y_test, y_pred))



from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Assuming X_train_scaled, X_test_scaled, y_train, and y_test are already defined

# Initialize base classifiers
logistic_regression = LogisticRegression()
random_forest = RandomForestClassifier()

# Create a Voting Classifier with soft voting
voting_classifier = VotingClassifier(estimators=[
    ('lr', logistic_regression),
    ('rf', random_forest)
], voting='soft')

# Fit the Voting Classifier to the training data
voting_classifier.fit(X_train_scaled, y_train)

# Predict on the test set
y_pred = voting_classifier.predict(X_test_scaled)

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Test Accuracy:", accuracy)




